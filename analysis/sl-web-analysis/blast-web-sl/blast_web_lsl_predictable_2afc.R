#  BLAST TSL Analysis
#  Violet Kozloff
#  Last updated April 17th, 2019 
#  Adapted from mturk_lsl by An Nguyen
#  This script analyses reaction time for LSL files from the online session of the BLAST experiment
#  ****************************************************************************

# Prepare workspace ------------------------------------------------------------

# Set directory
setwd("/Volumes/data/projects/blast/data/online_sl/blast_adult/predictable_lsl")
# NOTE: Comment out the above line and use this one for children
# setwd("/Volumes/data-1/projects/blast/data/online_sl/blast_child/predictable_lsl")
# setwd("/Volumes/data/projects/spoli/raw_sl_data")

install.packages("reshape")
library("reshape")
install.packages("DescTools")
library("DescTools")



# Remove objects in environment
rm(list=ls())

# Output path
output_path <- ("/Volumes/data/projects/blast/data_summaries/blast_online_adult/breakdown/")
# output_path <- ("/Volumes/data/projects/blast/data_summaries/blast_online_child/breakdown/")


#importing files

# List input files
lsl_files <- list.files(pattern="*lsl.csv")

# TO DO: This should change for corrected LSL files
language = list(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2)

# Initialize variable to hold data
lsl <- NULL

# Extract relevant data and combine it
for (file in lsl_files){
  # Select only relevant columns
  extracted_data <- read.csv(file)[c("rt", "trial_index", "targ","key_press", "stimulus", "animation_sequence")]  
  # Create a column populated with the participant ID based on the file name
  extracted_data["part_id"] <- substr(basename(file), 1, 11)
  # Change target and stimulus to string
  extracted_data["targ"] <- as.character(extracted_data$targ)
  extracted_data["stimulus"] <- as.character(extracted_data$stimulus)
  # The keypress value recorded as "rt" in the raw files is not the true reaction time. Rename the column. See below for details on how to use this value.
  colnames(extracted_data)[colnames(extracted_data)=="rt"] <- "press_time"
  # Standardize stimulus names and types
  extracted_data$stimulus<- gsub(".png","", extracted_data$stimulus)
  extracted_data$stimulus<- gsub("image/image/","",extracted_data$stimulus)
  extracted_data$stimulus<- gsub("image/","",extracted_data$stimulus)
  extracted_data$press_time<-as.numeric(extracted_data$press_time)
  # Identify blank keypresses
  extracted_data[which(extracted_data$press_time==-1),]$press_time<-NA
  # Identify preceding and following stimuli
  extracted_data$prev_stim <- append(NA, (head(extracted_data$stimulus, -1)))
  extracted_data$next_stim <- append(extracted_data$stimulus[-1], NA)
  # Combine data from current file
  lsl<-rbind(lsl,extracted_data)
}


# Calculate and summarize individual accuracies ------------------------------------------------------------

#Extract the test phase
test_phase <- lsl[(lsl$stimulus=="white" & !lsl$key_press==-1),]

#Internal check: this should be exactly 32 (32 forced choices per participant)
# TO DO: Make this automatic so it just warns user if participant doesn't have exactly 32
View(length(test_phase$targ)/length(unique(test_phase$part_id)))

ans <- NULL
keyv <- NULL
subj <- NULL

#Extract rows in which the participant gives a response
row_numberv <- which(test_phase$key_press != -1 & test_phase$stimulus == "white")
for (i in row_numberv){
  ans<-append(ans,test_phase[i,]$key_press)
  subj <- append(subj,paste(test_phase[i,]$part_id))
}

# Create a data frame that contains the participants' responses
lsl_accuracy <- data.frame(ans,subj)
lsl_accuracy <- lsl_accuracy[!(lsl_accuracy$ans==32),]

keyv<- NULL

i=0

# Combine the answer keys for the two language conditions that the participant saw
keyv <- rep(language, times = length(unique(lsl_accuracy$subj)))

# Find all of the IDs for the participants whose accuracy you're calculating
acc_id <- unique(lsl_accuracy$subj)

lsl_accuracy$key <- keyv

#Substitute the key press (49,50) with the answer (1,2)
lsl_accuracy$ans <- gsub(50,2,lsl_accuracy$ans)
lsl_accuracy$ans <- gsub(49,1,lsl_accuracy$ans)

# Code answers as correct or incorrect
corr <- NULL
for (i in seq(from=1,to=length(lsl_accuracy$ans),by=1)) {corr<-append(corr,as.numeric(lsl_accuracy[i,]$ans==lsl_accuracy[i,]$key))}
lsl_accuracy$corr <- corr


# Entropy

# Read in the entropy key
lsl_entropy_key <- read.csv("/Volumes/data/projects/blast/data/online_sl/entropy_keys/lsl_entropy_key_predictable.csv")
lsl_entropy_key <- (lsl_entropy_key[c("target_type","target_order","target_occurance_order","letter_target")])


# Entropy

# Find the triplet type (each triplet gets coded with a value from A-D)
triplet_type <- rep(lsl_entropy_key$target_type, times = length(unique(lsl_accuracy$subj)))
# Find the order for the triplet (the triplet either appeared first or second, with respect to the foil)
triplet_order <- rep(lsl_entropy_key$target_order, times = length(unique(lsl_accuracy$subj)))
# Find the occurance for the triplet (each triplet occurs between 7 and 9 times. Number each occurance.)
triplet_occurance <- rep(lsl_entropy_key$target_occurance_order, times = length(unique(lsl_accuracy$subj)))
# Find the letter triplet (which three syllables make up the triplet)
letter_triplet <- rep(lsl_entropy_key$letter_target, times = length(unique(lsl_accuracy$subj)))

lsl_accuracy$triplet_type <- triplet_type
lsl_accuracy$triplet_order <- triplet_order
lsl_accuracy$triplet_occurance <- triplet_occurance
lsl_accuracy$letter_triplet <- letter_triplet

# Entropy
lsl_entropy_wide<- cast(lsl_accuracy, subj~corr+triplet_type, value = "letter_triplet", fun.aggregate = length)


#Caculate Entropy for each target type by group and by task
lsl_entropy_by_triplet <- data.frame()

# LSL Entropy for each target type
for (i in 1:nrow(lsl_entropy_wide)) {
  lsl_entropy_by_triplet[i,"lsl_a_entropy"] <- Entropy(lsl_entropy_wide[i,c("0_A","1_A")])
}

for (i in 1:nrow(lsl_entropy_wide)) {
  lsl_entropy_by_triplet[i,"lsl_b_entropy"] <- Entropy(lsl_entropy_wide[i,c("0_B","1_B")])
}

for (i in 1:nrow(lsl_entropy_wide)) {
  lsl_entropy_by_triplet[i,"lsl_c_entropy"] <- Entropy(lsl_entropy_wide[i,c("0_C","1_C")])
}

for (i in 1:nrow(lsl_entropy_wide)) {
  lsl_entropy_by_triplet[i,"lsl_d_entropy"] <- Entropy(lsl_entropy_wide[i,c("0_D","1_D")])
}

for (i in 1:nrow(lsl_entropy_wide)) {
  lsl_entropy_by_triplet[i,"part_id"] <- lsl_entropy_wide[i,c("subj")]
}

lsl_entropy_by_triplet$mean_entropy <- round(rowMeans(lsl_entropy_by_triplet[,1:4], na.rm = FALSE, dims = 1), 3)

write.csv(lsl_entropy_by_triplet[,5:6], paste0(output_path, "online_lsl_predictable_entropy_adults.csv"))




# Count correct answers

subj_corr <- NULL
for (id in acc_id) {subj_corr <- append(subj_corr,round(sum(lsl_accuracy$corr[lsl_accuracy$subj==id])/32,digits=3))}
lsl_acc_table <- data.frame(acc_id,subj_corr)

write.csv(lsl_acc_table, paste0(output_path, "online_lsl_predictable_2afc_accuracies.csv"))



# 
# # RT Slope Analysis ----------------------------------------------
# 
# lsl <- read.csv("/Users/vkozloff/Documents/blast_adult_web_sl_data/clean/lsl_clean/lsl.csv")
# 
# lsl$stim_disp<- gsub("image/","",lsl$stim_disp)
# lsl$stim_disp<- gsub(".png","",lsl$stim_disp)
# lsl$stim_disp<- tolower(lsl$stim_disp)
# 
# 
# # Find the rows when the participant responded to the target
# row_number <- which(lsl$targ==lsl$stim_disp)
# 
# rt_col <- NULL
# id <- NULL
# trial <- NULL
# for (i in row_number){
#   rt_col <- append(rt_col,lsl[i,][,"time"])
#   trial <- append(trial,lsl[i,][,"X"])
#   id <- append(id,paste(lsl[i,]$part_id))
#   if (!is.na(lsl[i+1,][,"time"])){
#     rt_col[(match(i,row_number))] <- (480+lsl[i+1,][,"time"])
#     # TO DO: This was formerly an "if" statement, but I don't get how any reaction could fit into both? 
#     # And they're all negative otherwise?
#   } 
#   if (!is.na(lsl[i-1,][,"time"])){
#     rt_col[(match(i,row_number))] <- (0-lsl[i+1,][,"time"])
#   }
# }
# 
# 
# #analysis on RT
# # Numbers might change file to file. May have an extra blank stimulus before it.
# # TO DO: Check that these chunks are generally correct
# fam_trial <- data.frame(unlist(trial),unlist(rt_col),id)
# colnames(fam_trial) <- c("trial","rt_col","id")
# 
# #Re-index the trial number of the response so that it ranges from 1-24 (because there are 24 stimuli in total)
# reindex <- rep(1:24,length(fam_trial$trial)/24)
# fam_trial$reindex <- reindex
# 
# hit_rate <- NULL
# miss_rate <- NULL
# correct_rejection <- NULL
# false_alarm <- NULL
# mean_rt <- NULL
# rt_slope <- NULL
# 
# # TO DO: Restricting answers in a range of -1000-1000 gives a very low number of responses. 
# # Something off about the scale?
# #only accept answers in range of -1000 < x < 1000
# mean_table <- fam_trial[which(fam_trial$rt_col!=-1),] #& fam_trial$rt_col<1000 & fam_trial$rt_col>-1000), ] 
# 
# #TO DO: exclude data that only press 1 (so rt slope cannot be computed)
# 
# list_lsl_id <- unique(mean_table$id)
# mean_table$part_id<-mean_table$id
# 
# #Extract the mean response time, rt slope, hit rate, miss rat, correct rejection, and false alarm for each participant
# for(id in list_lsl_id){
#   mean_rt<-append(mean_rt,round(mean(mean_table$rt_col[mean_table$part_id==id]),digits=3))
#   rt_slope <-append(rt_slope,round(summary(lm(mean_table$rt_col[mean_table$part_id==id]~mean_table$reindex[mean_table$id==id]))$coefficient[2,1],digits=3))
#   
#   hit_rate<-append(hit_rate,round(sum(!is.na(mean_table$rt_col[mean_table$part_id==id]))/24,digits =2))
#   
#   miss_rate<-append(miss_rate,round(sum(is.na(fam_trial$rt_col[fam_trial$part_id==id]))/24,digits =2))
#   
#   correct_rejection <- append(correct_rejection,  round(sum(is.na(lsl$rt[lsl$part_id==id]) & lsl$target[lsl$par_id==id]!=lsl$stim_disp[lsl$par_id==id])/552,digits=2) )  #552 is the total number of stimuli in the familiarization block
#   false_alarm <- append(false_alarm, round(sum(!is.na(lsl$rt[lsl$par_id==id]) & lsl$target[lsl$par_id==id]!=lsl$stim_disp[lsl$par_id==id])/552,digits=2) ) }
# 
# subj_table <- data.frame(list_lsl_id,mean_rt, rt_slope,hit_rate, miss_rate,correct_rejection,false_alarm)
# 
# # TO DO: Deal with all the warnings that come here? Idk why? 
# # Something is funky with the rts, which seem to be the presentation times and not response times?